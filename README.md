# Sistema de DetecciÃ³n de AnomalÃ­as - YPF

Sistema completo de detecciÃ³n de anomalÃ­as en tiempo real para variables de proceso industrial utilizando **Facebook Prophet**. El sistema estÃ¡ diseÃ±ado para integrarse con SQL Server y proporcionar detecciÃ³n continua de anomalÃ­as.

## ğŸ¯ CaracterÃ­sticas Principales

- **DetecciÃ³n en Tiempo Real**: Procesamiento continuo de datos nuevos
- **Modelos Prophet**: Un modelo por variable con estacionalidad diaria y semanal
- **IntegraciÃ³n SQL Server**: Lectura y escritura en bases de datos separadas
- **Workers AutomÃ¡ticos**: Procesamiento incremental y reentrenamiento automÃ¡tico
- **Dashboard Streamlit**: GuÃ­a completa para desarrolladores front-end
- **MÃ©tricas de EvaluaciÃ³n**: Sistema completo de evaluaciÃ³n de modelos

## ğŸ“‹ Tabla de Contenidos

- [Arquitectura](#arquitectura)
- [InstalaciÃ³n](#instalaciÃ³n)
- [ConfiguraciÃ³n](#configuraciÃ³n)
- [Uso RÃ¡pido](#uso-rÃ¡pido)
- [DocumentaciÃ³n](#documentaciÃ³n)
- [Estructura del Proyecto](#estructura-del-proyecto)

## ğŸ—ï¸ Arquitectura

El sistema utiliza una arquitectura en capas:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   SQL Server (Datos)                     â”‚
â”‚   â€¢ otms_main.ypf_process_data          â”‚
â”‚   â€¢ otms_analytics.ypf_anomaly_detector â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Capa de AplicaciÃ³n                     â”‚
â”‚   â€¢ ProphetAnomalyDetector               â”‚
â”‚   â€¢ SQLConnection                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Capa de Procesamiento                 â”‚
â”‚   â€¢ Workers (tiempo real)               â”‚
â”‚   â€¢ Scripts batch                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

Para mÃ¡s detalles, ver [ARQUITECTURA.md](ARQUITECTURA.md)

## ğŸš€ InstalaciÃ³n

### Requisitos

- Python 3.8+
- SQL Server (con acceso a las bases de datos)
- ODBC Driver 17 for SQL Server

### InstalaciÃ³n de Dependencias

```bash
# Instalar dependencias principales
pip install -r requirements_sql.txt

# Para el dashboard Streamlit (opcional)
pip install -r requirements_streamlit.txt
```

### Dependencias Principales

- `pandas>=1.5.0` - ManipulaciÃ³n de datos
- `numpy>=1.23.0` - CÃ¡lculos numÃ©ricos
- `prophet>=1.1.0` - Modelos de series temporales
- `pyodbc>=4.0.0` - ConexiÃ³n a SQL Server
- `streamlit>=1.28.0` - Dashboard (opcional)
- `plotly>=5.17.0` - Visualizaciones (opcional)

## âš™ï¸ ConfiguraciÃ³n

### ConfiguraciÃ³n de Base de Datos

El sistema requiere dos bases de datos:

1. **Base de Datos de Entrada**: `otms_main`
   - Tabla: `ypf_process_data`
   - Formato: `(datetime, variable_name, value)`

2. **Base de Datos de Salida**: `otms_analytics`
   - Tabla: `ypf_anomaly_detector`
   - Contiene resultados de detecciÃ³n

### ConfiguraciÃ³n de ConexiÃ³n

Edita los archivos de configuraciÃ³n SQL en:
- `detect_from_sql.py`
- `train_from_sql.py`
- `worker_procesamiento.py`
- `worker_reentrenamiento.py`

```python
SQL_CONFIG_INPUT = {
    'server': 'tu_servidor',
    'database': 'otms_main',
    'username': 'usuario',
    'password': 'contraseÃ±a',
    'port': 1433
}

SQL_CONFIG_OUTPUT = {
    'server': 'tu_servidor',
    'database': 'otms_analytics',
    'username': 'usuario',
    'password': 'contraseÃ±a',
    'port': 1433
}
```

## ğŸ® Uso RÃ¡pido

### 1. Entrenar Modelos

```bash
# Desde SQL Server
python train_from_sql.py

# Desde archivos CSV
python pipeline/scripts/train_anomaly_detector.py
```

### 2. Detectar AnomalÃ­as

```bash
# Procesamiento batch (todos los datos)
python detect_from_sql.py

# Procesamiento en tiempo real (worker)
python worker_procesamiento.py
```

### 3. Evaluar Modelos

```bash
python evaluar_modelo.py
```

### 4. Dashboard de GuÃ­a Front-End

```bash
streamlit run guia_frontend_streamlit.py
```

## ğŸ“š DocumentaciÃ³n

- **[ARQUITECTURA.md](ARQUITECTURA.md)**: Arquitectura completa del sistema
- **[README_SQL.md](README_SQL.md)**: GuÃ­a de integraciÃ³n con SQL Server
- **[README_WORKER.md](README_WORKER.md)**: DocumentaciÃ³n de workers
- **[README_TIEMPO_REAL.md](README_TIEMPO_REAL.md)**: Procesamiento en tiempo real

## ğŸ“ Estructura del Proyecto

```
ypf_anomalies_detector/
â”œâ”€â”€ pipeline/
â”‚   â”œâ”€â”€ scripts/
â”‚   â”‚   â”œâ”€â”€ prophet_anomaly_detector.py    # Clase principal
â”‚   â”‚   â”œâ”€â”€ train_anomaly_detector.py      # Entrenamiento
â”‚   â”‚   â””â”€â”€ detect_anomalies.py            # DetecciÃ³n
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ prophet/                       # Modelos entrenados
â”‚   â””â”€â”€ results/                          # Resultados
â”œâ”€â”€ sql_utils.py                           # Utilidades SQL
â”œâ”€â”€ train_from_sql.py                      # Entrenar desde SQL
â”œâ”€â”€ detect_from_sql.py                     # Detectar desde SQL
â”œâ”€â”€ worker_procesamiento.py                # Worker principal
â”œâ”€â”€ worker_reentrenamiento.py              # Worker reentrenamiento
â”œâ”€â”€ evaluar_modelo.py                      # EvaluaciÃ³n de modelos
â”œâ”€â”€ guia_frontend_streamlit.py             # Dashboard Streamlit
â”œâ”€â”€ requirements_sql.txt                   # Dependencias SQL
â”œâ”€â”€ requirements_streamlit.txt             # Dependencias Streamlit
â””â”€â”€ README.md                              # Este archivo
```

## ğŸ”§ Componentes Principales

### ProphetAnomalyDetector

Clase principal para detecciÃ³n de anomalÃ­as:

```python
from pipeline.scripts.prophet_anomaly_detector import ProphetAnomalyDetector

detector = ProphetAnomalyDetector(
    interval_width=0.95,
    anomaly_threshold=2.0
)

# Entrenar
detector.train_multiple_variables(df, variables)

# Detectar
results = detector.detect_anomalies_multiple(df, variables)
```

### SQLConnection

Utilidad para conexiÃ³n a SQL Server:

```python
from sql_utils import SQLConnection

conn = SQLConnection(server, database, username, password, port)
conn.connect()

# Leer datos
df = conn.execute_query("SELECT * FROM tabla")

# Escribir datos
conn.write_dataframe(df, "tabla")
```

## ğŸ“Š Resultados

El sistema genera los siguientes campos:

- `ds`: Fecha y hora del dato
- `y`: Valor real observado
- `yhat`: Valor predicho por el modelo
- `yhat_lower/upper`: Intervalo de confianza (95%)
- `is_anomaly`: Indicador de anomalÃ­a (0/1)
- `anomaly_score`: Score de anomalÃ­a (0-100)
- `variable`: Nombre de la variable
- `residual`: Diferencia entre real y predicho

## ğŸ”„ Flujo de Trabajo

### Modo Batch

1. Leer datos desde SQL
2. Transformar formato (largo â†’ ancho)
3. Cargar modelos Prophet
4. Detectar anomalÃ­as
5. Escribir resultados a SQL

### Modo Tiempo Real

1. Worker verifica nuevos datos cada X minutos
2. Procesa solo datos nuevos (incremental)
3. Escribe resultados inmediatamente
4. Actualiza Ãºltimo datetime procesado

## ğŸ¨ Dashboard Streamlit

El dashboard `guia_frontend_streamlit.py` proporciona:

- Visualizaciones interactivas de anomalÃ­as
- Queries SQL de ejemplo
- GuÃ­a para desarrolladores front-end
- Vista del operario (dashboard real)

Ejecutar:
```bash
streamlit run guia_frontend_streamlit.py
```

## ğŸ“ˆ MÃ©tricas del Modelo

El sistema incluye evaluaciÃ³n completa:

- **MAE, RMSE, MAPE**: MÃ©tricas de predicciÃ³n
- **RÂ²**: Coeficiente de determinaciÃ³n
- **Cobertura del Intervalo**: ValidaciÃ³n del 95%
- **DistribuciÃ³n de Scores**: AnÃ¡lisis de severidad

Ejecutar evaluaciÃ³n:
```bash
python evaluar_modelo.py
```

## ğŸ” Seguridad

âš ï¸ **Importante**: No subir credenciales a Git. Usa variables de entorno o archivos de configuraciÃ³n locales (no versionados).

## ğŸ¤ ContribuciÃ³n

1. Fork el proyecto
2. Crea una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

## ğŸ“ Licencia

Este proyecto es privado y confidencial.

## ğŸ‘¤ Autor

AndrÃ©s RÃ­os

## ğŸ™ Agradecimientos

- Facebook Prophet para el modelo de series temporales
- Comunidad de Python para las librerÃ­as utilizadas
